{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30565,
     "status": "ok",
     "timestamp": 1613352093074,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "Cno7yx834OhI",
    "outputId": "f0e6843e-baff-4b91-8179-459f4d9f7f5f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras as k\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1613352138483,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "lFJtP5tcw-0E",
    "outputId": "f5d478bd-ba49-45b6-b997-fdf8e73ecf44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 123] The filename, directory name, or volume label syntax is incorrect: \"'E:\\\\Stevens\\\\Spring 2021\\\\Research\\\\Stevens_AM_lab'\"\n",
      "C:\\Users\\Dalli\\Desktop\\jiaqi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dalli\\\\Desktop\\\\jiaqi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd 'E:\\Stevens\\Spring 2021\\Research\\Stevens_AM_lab'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bOY7oWKxYPGI"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def TicTocGenerator():\n",
    "    # Generator that returns time differences\n",
    "    ti = 0           # initial time\n",
    "    tf = time.time() # final time\n",
    "    while True:\n",
    "        ti = tf\n",
    "        tf = time.time()\n",
    "        yield tf-ti # returns the time difference\n",
    "\n",
    "TicToc = TicTocGenerator() # create an instance of the TicTocGen generator\n",
    "\n",
    "# This will be the main function through which we define both tic() and toc()\n",
    "def toc(tempBool=True):\n",
    "    # Prints the time difference yielded by generator instance TicToc\n",
    "    tempTimeInterval = next(TicToc)\n",
    "    if tempBool:\n",
    "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval )\n",
    "\n",
    "def tic():\n",
    "    # Records a time in TicToc, marks the beginning of a time interval\n",
    "    toc(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "executionInfo": {
     "elapsed": 1500200,
     "status": "error",
     "timestamp": 1613353642054,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "0SGvIAO84Qp_",
    "outputId": "f59c418f-a4b7-4937-80d4-b75646c34870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty\n",
      "0\n",
      "Elapsed time: 0.310009 seconds.\n",
      "\n",
      "1000\n",
      "Elapsed time: 2.451142 seconds.\n",
      "\n",
      "2000\n",
      "Elapsed time: 1.691430 seconds.\n",
      "\n",
      "3000\n",
      "Elapsed time: 1.662099 seconds.\n",
      "\n",
      "OK\n",
      "0\n",
      "Elapsed time: 0.270312 seconds.\n",
      "\n",
      "1000\n",
      "Elapsed time: 11.049730 seconds.\n",
      "\n",
      "2000\n",
      "Elapsed time: 11.683376 seconds.\n",
      "\n",
      "3000\n",
      "Elapsed time: 11.675758 seconds.\n",
      "\n",
      "4000\n",
      "Elapsed time: 20.722862 seconds.\n",
      "\n",
      "5000\n",
      "Elapsed time: 14.025158 seconds.\n",
      "\n",
      "6000\n",
      "Elapsed time: 13.760969 seconds.\n",
      "\n",
      "7000\n",
      "Elapsed time: 18.550912 seconds.\n",
      "\n",
      "8000\n",
      "Elapsed time: 14.182205 seconds.\n",
      "\n",
      "9000\n",
      "Elapsed time: 17.195850 seconds.\n",
      "\n",
      "10000\n",
      "Elapsed time: 14.488771 seconds.\n",
      "\n",
      "11000\n",
      "Elapsed time: 13.857116 seconds.\n",
      "\n",
      "12000\n",
      "Elapsed time: 14.245243 seconds.\n",
      "\n",
      "13000\n",
      "Elapsed time: 12.714983 seconds.\n",
      "\n",
      "Over\n",
      "0\n",
      "Elapsed time: 4.512597 seconds.\n",
      "\n",
      "1000\n",
      "Elapsed time: 2.908859 seconds.\n",
      "\n",
      "2000\n",
      "Elapsed time: 2.869027 seconds.\n",
      "\n",
      "3000\n",
      "Elapsed time: 3.225779 seconds.\n",
      "\n",
      "4000\n",
      "Elapsed time: 3.131212 seconds.\n",
      "\n",
      "5000\n",
      "Elapsed time: 3.582546 seconds.\n",
      "\n",
      "6000\n",
      "Elapsed time: 3.861322 seconds.\n",
      "\n",
      "7000\n",
      "Elapsed time: 3.812706 seconds.\n",
      "\n",
      "8000\n",
      "Elapsed time: 3.888147 seconds.\n",
      "\n",
      "9000\n",
      "Elapsed time: 4.074208 seconds.\n",
      "\n",
      "10000\n",
      "Elapsed time: 3.864867 seconds.\n",
      "\n",
      "11000\n",
      "Elapsed time: 3.773664 seconds.\n",
      "\n",
      "12000\n",
      "Elapsed time: 3.909397 seconds.\n",
      "\n",
      "Under\n",
      "0\n",
      "Elapsed time: 0.601426 seconds.\n",
      "\n",
      "1000\n",
      "Elapsed time: 12.314210 seconds.\n",
      "\n",
      "2000\n",
      "Elapsed time: 10.629744 seconds.\n",
      "\n",
      "3000\n",
      "Elapsed time: 10.709249 seconds.\n",
      "\n",
      "4000\n",
      "Elapsed time: 10.826003 seconds.\n",
      "\n",
      "5000\n",
      "Elapsed time: 11.518232 seconds.\n",
      "\n",
      "6000\n",
      "Elapsed time: 10.788203 seconds.\n",
      "\n",
      "7000\n",
      "Elapsed time: 10.305827 seconds.\n",
      "\n",
      "8000\n",
      "Elapsed time: 10.411196 seconds.\n",
      "\n",
      "9000\n",
      "Elapsed time: 11.147693 seconds.\n",
      "\n",
      "10000\n",
      "Elapsed time: 11.634900 seconds.\n",
      "\n",
      "11000\n",
      "Elapsed time: 10.106457 seconds.\n",
      "\n",
      "12000\n",
      "Elapsed time: 10.165458 seconds.\n",
      "\n",
      "13000\n",
      "Elapsed time: 10.400526 seconds.\n",
      "\n",
      "14000\n",
      "Elapsed time: 9.771914 seconds.\n",
      "\n",
      "Elapsed time: 8.425093 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "def create_dataset(img_folder,IMG_HEIGHT=30, IMG_WIDTH=30):\n",
    "    tic()\n",
    "    i=1\n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        print(dir1)\n",
    "        files = os.listdir(os.path.join(img_folder, dir1))\n",
    "        shuffle(files)\n",
    "        i=0\n",
    "        for file in files:\n",
    "          if file.endswith('.png'):\n",
    "            if (i%1000 == 0):\n",
    "              print(i)\n",
    "              toc()\n",
    "              tic()\n",
    "            #if (i == 2000):\n",
    "              #break\n",
    "            i = i+1\n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            image=np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255 \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    return img_data_array, class_name\n",
    "\n",
    "# extract the image array and class name\n",
    "img_folder=r'E:\\Stevens\\Spring 2021\\Research\\Stevens_AM_lab\\Test_data_labeled\\labeled'\n",
    "img_data, class_name =create_dataset(img_folder)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in e:\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in e:\\anaconda3\\lib\\site-packages (from scipy) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1613338115806,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "O3EbQ-bAKlKE",
    "outputId": "23fdd1d2-169d-4f5a-ef3f-dae05f804b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Empty' 'Empty' 'Empty' ... 'Under' 'Under' 'Under']\n",
      "[0 0 0 ... 3 3 3]\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "['Empty']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define example\n",
    "data = class_name\n",
    "values = array(data)\n",
    "print(values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[1001, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1613338123521,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "iPlOl9ctYZeh",
    "outputId": "7822222e-8c3c-452f-b02c-e380dbe69168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Empty']\n"
     ]
    }
   ],
   "source": [
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[999, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GbO3L2K-Rf5F"
   },
   "outputs": [],
   "source": [
    "class Same_net(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                     filters_1x1=16,\n",
    "                     filters_3x3_reduce=16,\n",
    "                     filters_3x3=16,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=16,\n",
    "                     filters_pool_proj=16,\n",
    "                     name='inception_3a',\n",
    "                     inp_shapes = (30, 30, 3)):\n",
    "      \n",
    "        super(Same_net, self).__init__()\n",
    "        self.conv1x1 = tf.keras.layers.Conv2D(filters_1x1, (1, 1), padding='same')\n",
    "        \n",
    "        self.conv3x3_reduce = tf.keras.layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same')\n",
    "        self.conv3x3 = tf.keras.layers.Conv2D(filters_3x3, (3, 3), padding='same')\n",
    "        \n",
    "        self.conv5x5_reduce = tf.keras.layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same')\n",
    "        self.conv5x5 = tf.keras.layers.Conv2D(filters_5x5, (5, 5), padding='same')\n",
    "        \n",
    "        self.convpool = tf.keras.layers.Conv2D(filters_1x1, (1, 1), padding='same')\n",
    "        \n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D((3, 3),strides=(1, 1), padding='same')\n",
    "        self.Concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        b1 = self.conv1x1(inputs)\n",
    "        b1_act = self.act(b1)\n",
    "        \n",
    "        b2 = self.conv3x3_reduce(inputs)\n",
    "        b2_act = self.act(b2)\n",
    "        b2_2 = self.conv3x3(b2_act)\n",
    "        b2_2_act = self.act(b2_2)\n",
    "        \n",
    "        b3 = self.conv5x5_reduce(inputs)\n",
    "        b3_act = self.act(b3)\n",
    "        b3_2 = self.conv5x5(b3_act)\n",
    "        b3_2_act = self.act(b3_2)\n",
    "        \n",
    "        b4 = self.max_pool(inputs)\n",
    "        b4_2 = self.convpool(b4)\n",
    "        b4_2_act = self.act(b4_2)\n",
    "               \n",
    "        output = self.Concat([b1_act, b2_2_act, b3_2_act, b4_2_act])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3xpYkVHWLcuy"
   },
   "outputs": [],
   "source": [
    "class Encod_2(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=16):\n",
    "        super(Encod_2, self).__init__()\n",
    "        self.conv1x1 = tf.keras.layers.Conv2D(filters_1x1, (3, 3), padding='same')\n",
    "        self.conv1x1_2 = tf.keras.layers.Conv2D(filters_1x1, (3, 3), padding='same')\n",
    "        self.max_pool2 = tf.keras.layers.MaxPool2D((2,2),strides=(2, 2), padding='same')\n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "    def call(self, inputs):\n",
    "        b1 = self.conv1x1(inputs)\n",
    "        b1_act = self.act(b1)  \n",
    "        b2 = self.conv1x1_2(b1_act)\n",
    "        b2_act = self.act(b2)  \n",
    "        b3 =   self.max_pool2(b2_act) \n",
    "        return b3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mSsokzAHFq9Z"
   },
   "outputs": [],
   "source": [
    "class Encod_comp(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=16):\n",
    "        super(Encod_comp, self).__init__()\n",
    "        self.b1 = Same_net()\n",
    "        self.b12 = Same_net()\n",
    "        self.b13 = Same_net()\n",
    "        \n",
    "        self.b2 = Encod_2()\n",
    "        self.b22 = Encod_2()\n",
    "        self.b23 = Encod_2()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        l1 = self.b1(inputs)\n",
    "        l2 = self.b2(l1)\n",
    "        l3 = self.b12(l2)\n",
    "        l4 = self.b22(l3)\n",
    "        l5 = self.b13(l4)\n",
    "        #l6 = self.b23(l5)\n",
    "\n",
    "               \n",
    "        return l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OiigzT0fHtN9"
   },
   "outputs": [],
   "source": [
    "class Class_out(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=8):\n",
    "        super(Class_out, self).__init__()\n",
    "        self.Flat = tf.keras.layers.Flatten()\n",
    "        self.D1 = tf.keras.layers.Dense(150, activation='relu')\n",
    "        self.D2 = tf.keras.layers.Dense(40, activation='relu')\n",
    "        self.D3 = tf.keras.layers.Dense(12, activation='relu')\n",
    "        self.D4 = tf.keras.layers.Dense(4, activation='softmax')\n",
    "        #self.D5 = tf.keras.layers.Softmax()\n",
    "        #self.D0 = Encod_comp()\n",
    "\n",
    "    def call(self, inputs):\n",
    "      \n",
    "        #l0 = self.D0(inputs)\n",
    "        #l1 = self.Flat(l0)\n",
    "\n",
    "        l1 = self.Flat(inputs)\n",
    "        l2 = self.D1(l1)\n",
    "        l3 = self.D2(l2)\n",
    "        l4 = self.D3(l3)\n",
    "        l5 = self.D4(l4)\n",
    "        #l6 = self.D5(l5)\n",
    "               \n",
    "        return l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZZfX3yUUtR6w"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=16,same_pad = 0,up_sample=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        if (same_pad == 1):\n",
    "          self.conv1x1 = tf.keras.layers.Conv2DTranspose(filters_1x1, (3, 3), padding='same')\n",
    "          self.conv1x1_2 = tf.keras.layers.Conv2DTranspose(filters_1x1, (3, 3), padding='same')\n",
    "        elif (same_pad == 0):\n",
    "          self.conv1x1 = tf.keras.layers.Conv2DTranspose(filters_1x1, (3, 3), padding='valid')\n",
    "          self.conv1x1_2 = tf.keras.layers.Conv2DTranspose(filters_1x1, (3, 3), padding='valid')\n",
    "        else:\n",
    "           self.conv1x1 = tf.keras.layers.Conv2D(filters_1x1, (3, 3))\n",
    "           self.conv1x1_2 = tf.keras.layers.Conv2DTranspose(filters_1x1, (3, 3), padding='same')\n",
    "        if up_sample :\n",
    "          self.UpSampling2D = tf.keras.layers.UpSampling2D((2, 2), interpolation='bilinear')\n",
    "        else:\n",
    "          self.UpSampling2D = tf.keras.layers.UpSampling2D((1, 1), interpolation='bilinear')\n",
    "        self.act = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "        self.conv_reduce = tf.keras.layers.Conv2D(filters_1x1, (3, 3))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        b1 = self.conv1x1(inputs)\n",
    "        b1_act = self.act(b1)  \n",
    "        b2 = self.conv1x1_2(b1_act)\n",
    "        b2_act = self.act(b2)  \n",
    "        b3 =   self.UpSampling2D(b2_act) \n",
    "        return b3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oGyDUMRC881e"
   },
   "outputs": [],
   "source": [
    "class Decod_comp(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=8):\n",
    "        super(Decod_comp, self).__init__()\n",
    "        self.b1 = Same_net()\n",
    "        self.b12 = Same_net()\n",
    "        self.b13 = Same_net()\n",
    "        self.b14 = Same_net()\n",
    "        \n",
    "        self.b2 = Decoder(same_pad = 1,up_sample=1)\n",
    "        self.b22 = Decoder(same_pad = 1,up_sample=1)\n",
    "        self.b23 = Decoder(same_pad = 1,up_sample=0)\n",
    "        self.b24 = Decoder(filters_1x1=3,same_pad = 2,up_sample=0)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        l1 = self.b1(inputs)\n",
    "        l2 = self.b2(l1)\n",
    "        l3 = self.b12(l2)\n",
    "        l4 = self.b22(l3)\n",
    "        l5 = self.b13(l4)\n",
    "        l6 = self.b23(l5)\n",
    "        l7 = self.b14(l6)\n",
    "        l8 = self.b24(l7)\n",
    "\n",
    "               \n",
    "        return l8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wVb1oBEI_mms"
   },
   "outputs": [],
   "source": [
    "class Model_comp(tf.keras.Model):\n",
    "    def __init__(self,filters_1x1=6):\n",
    "        super(Model_comp, self).__init__()\n",
    "        self.encoder = Encod_comp()\n",
    "        self.decoder = Decod_comp()\n",
    "        self.classifier = Class_out()\n",
    "    def call(self, inputs):\n",
    "        l1 = self.encoder(inputs)\n",
    "        l2 = self.decoder(l1)\n",
    "        l3 = self.classifier(l1)\n",
    "        return [l2,l3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ysR6AF-iQUcY"
   },
   "outputs": [],
   "source": [
    "img_data=np.array(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ve7QH6TBcpof"
   },
   "outputs": [],
   "source": [
    "model_1 =Model_comp()\n",
    "d = img_data[1:15]\n",
    "aa=model_1(d)\n",
    "##bb=model_1(aa[1:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bh6zeiOzTmMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34720 samples, validate on 8680 samples\n",
      "Epoch 1/20\n",
      "34720/34720 [==============================] - 569s 16ms/sample - loss: 0.7502 - output_1_loss: 0.1895 - output_2_loss: 0.5604 - output_1_accuracy: 0.6387 - output_2_accuracy: 0.7706 - val_loss: 1.0042 - val_output_1_loss: 0.1418 - val_output_2_loss: 0.8626 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.6975\n",
      "Epoch 2/20\n",
      "34720/34720 [==============================] - 556s 16ms/sample - loss: 0.5919 - output_1_loss: 0.1602 - output_2_loss: 0.4316 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8220 - val_loss: 0.9685 - val_output_1_loss: 0.1204 - val_output_2_loss: 0.8486 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.6876\n",
      "Epoch 3/20\n",
      "34720/34720 [==============================] - 555s 16ms/sample - loss: 0.5672 - output_1_loss: 0.1494 - output_2_loss: 0.4178 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8257 - val_loss: 0.7317 - val_output_1_loss: 0.1127 - val_output_2_loss: 0.6191 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7895\n",
      "Epoch 4/20\n",
      "34720/34720 [==============================] - 564s 16ms/sample - loss: 0.5519 - output_1_loss: 0.1450 - output_2_loss: 0.4068 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8304 - val_loss: 0.6811 - val_output_1_loss: 0.1104 - val_output_2_loss: 0.5708 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7828\n",
      "Epoch 5/20\n",
      "34720/34720 [==============================] - 559s 16ms/sample - loss: 0.5419 - output_1_loss: 0.1431 - output_2_loss: 0.3987 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8315 - val_loss: 0.8907 - val_output_1_loss: 0.1099 - val_output_2_loss: 0.7809 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.6972\n",
      "Epoch 6/20\n",
      "34720/34720 [==============================] - 557s 16ms/sample - loss: 0.5341 - output_1_loss: 0.1422 - output_2_loss: 0.3920 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8344 - val_loss: 0.7010 - val_output_1_loss: 0.1097 - val_output_2_loss: 0.5916 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7948\n",
      "Epoch 7/20\n",
      "34720/34720 [==============================] - 581s 17ms/sample - loss: 0.5235 - output_1_loss: 0.1418 - output_2_loss: 0.3816 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8394 - val_loss: 0.8286 - val_output_1_loss: 0.1098 - val_output_2_loss: 0.7191 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7245\n",
      "Epoch 8/20\n",
      "34720/34720 [==============================] - 588s 17ms/sample - loss: 0.5148 - output_1_loss: 0.1416 - output_2_loss: 0.3733 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8412 - val_loss: 0.8418 - val_output_1_loss: 0.1101 - val_output_2_loss: 0.7320 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7522\n",
      "Epoch 9/20\n",
      "34720/34720 [==============================] - 591s 17ms/sample - loss: 0.5043 - output_1_loss: 0.1415 - output_2_loss: 0.3630 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8466 - val_loss: 0.7057 - val_output_1_loss: 0.1103 - val_output_2_loss: 0.5953 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "34720/34720 [==============================] - 590s 17ms/sample - loss: 0.4942 - output_1_loss: 0.1414 - output_2_loss: 0.3529 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8501 - val_loss: 0.6189 - val_output_1_loss: 0.1108 - val_output_2_loss: 0.5088 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.8342\n",
      "Epoch 11/20\n",
      "34720/34720 [==============================] - 584s 17ms/sample - loss: 0.4770 - output_1_loss: 0.1415 - output_2_loss: 0.3354 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8568 - val_loss: 0.8965 - val_output_1_loss: 0.1103 - val_output_2_loss: 0.7866 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7287\n",
      "Epoch 12/20\n",
      "34720/34720 [==============================] - 588s 17ms/sample - loss: 0.4614 - output_1_loss: 0.1415 - output_2_loss: 0.3198 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8661 - val_loss: 1.1371 - val_output_1_loss: 0.1103 - val_output_2_loss: 1.0272 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.6749\n",
      "Epoch 13/20\n",
      "34720/34720 [==============================] - 584s 17ms/sample - loss: 0.4365 - output_1_loss: 0.1414 - output_2_loss: 0.2951 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8759 - val_loss: 0.8822 - val_output_1_loss: 0.1108 - val_output_2_loss: 0.7718 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7323\n",
      "Epoch 14/20\n",
      "34720/34720 [==============================] - 577s 17ms/sample - loss: 0.4141 - output_1_loss: 0.1415 - output_2_loss: 0.2726 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8857 - val_loss: 1.0736 - val_output_1_loss: 0.1105 - val_output_2_loss: 0.9634 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7008\n",
      "Epoch 15/20\n",
      "34720/34720 [==============================] - 576s 17ms/sample - loss: 0.3886 - output_1_loss: 0.1415 - output_2_loss: 0.2472 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.8978 - val_loss: 0.8952 - val_output_1_loss: 0.1102 - val_output_2_loss: 0.7851 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7781\n",
      "Epoch 16/20\n",
      "34720/34720 [==============================] - 572s 16ms/sample - loss: 0.3654 - output_1_loss: 0.1415 - output_2_loss: 0.2240 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.9081 - val_loss: 1.0020 - val_output_1_loss: 0.1103 - val_output_2_loss: 0.8925 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7689\n",
      "Epoch 17/20\n",
      "34720/34720 [==============================] - 584s 17ms/sample - loss: 0.3426 - output_1_loss: 0.1414 - output_2_loss: 0.2011 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.9192 - val_loss: 1.3709 - val_output_1_loss: 0.1106 - val_output_2_loss: 1.2617 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.6831\n",
      "Epoch 18/20\n",
      "34720/34720 [==============================] - 561s 16ms/sample - loss: 0.3218 - output_1_loss: 0.1414 - output_2_loss: 0.1804 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.9303 - val_loss: 1.1080 - val_output_1_loss: 0.1107 - val_output_2_loss: 0.9993 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7638\n",
      "Epoch 19/20\n",
      "34720/34720 [==============================] - 576s 17ms/sample - loss: 0.3002 - output_1_loss: 0.1415 - output_2_loss: 0.1588 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.9389 - val_loss: 1.1851 - val_output_1_loss: 0.1104 - val_output_2_loss: 1.0758 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7553\n",
      "Epoch 20/20\n",
      "34720/34720 [==============================] - 557s 16ms/sample - loss: 0.2843 - output_1_loss: 0.1415 - output_2_loss: 0.1428 - output_1_accuracy: 0.6521 - output_2_accuracy: 0.9473 - val_loss: 1.4533 - val_output_1_loss: 0.1101 - val_output_2_loss: 1.3448 - val_output_1_accuracy: 0.7796 - val_output_2_accuracy: 0.7285\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 400\n",
    "model_1 = Model_comp()\n",
    "model_1.compile(optimizer='adam', loss=['mean_squared_error' , 'categorical_crossentropy'], loss_weights=[1,1],metrics=['accuracy'])\n",
    "#model_1.compile(loss=\"mean_squared_error\", optimizer='RMSprop')\n",
    "history = model_1.fit(x=img_data,\n",
    "    y=[img_data, onehot_encoded],\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2421627,
     "status": "ok",
     "timestamp": 1612353189558,
     "user": {
      "displayName": "Javid Akhavan",
      "photoUrl": "",
      "userId": "10308335064462853553"
     },
     "user_tz": 300
    },
    "id": "jfWD5TIqiSGv",
    "outputId": "0117de7a-2045-4f54-e169-cb6133bf3736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CB814C8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CB92EC8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CBA5588>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.Encod_2 object at 0x000000E83CBBBC48>, because its inputs are not defined.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CBD2188>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CBE4A88>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CBF8288>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000000E83CC07A48>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CC16FC8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CC1F748>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CC2CE08>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CC38548>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CBBF208>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000000E83CBBF908>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000000E83CBBFF88>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Activation object at 0x000000E83CBC3548>, because it is not built.\n",
      "WARNING:tensorflow:From e:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 2_3_2021_6am.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save('2_3_2021_6am.tf')\n",
    "model_1.save_weights('2_3_2021_6am_weights.tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dUsI-mrWlMUz"
   },
   "outputs": [],
   "source": [
    "np.save('img_data',img_data)\n",
    "np.save('onehot_encoded',onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PZr4u714wz6m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34720 samples, validate on 8680 samples\n",
      "Epoch 1/10\n",
      "34720/34720 [==============================] - 547s 16ms/sample - loss: 0.2080 - output_1_loss: 0.0178 - output_2_loss: 0.1904 - output_1_accuracy: 0.7632 - output_2_accuracy: 0.9410 - val_loss: 0.4424 - val_output_1_loss: 0.0374 - val_output_2_loss: 0.4046 - val_output_1_accuracy: 0.8289 - val_output_2_accuracy: 0.8607\n",
      "Epoch 2/10\n",
      "34720/34720 [==============================] - 549s 16ms/sample - loss: 0.1325 - output_1_loss: 0.0173 - output_2_loss: 0.1153 - output_1_accuracy: 0.7557 - output_2_accuracy: 0.9626 - val_loss: 0.4466 - val_output_1_loss: 0.0371 - val_output_2_loss: 0.4092 - val_output_1_accuracy: 0.8317 - val_output_2_accuracy: 0.8797\n",
      "Epoch 3/10\n",
      "14144/34720 [===========>..................] - ETA: 5:40:10 - loss: 0.0928 - output_1_loss: 0.0169 - output_2_loss: 0.0758 - output_1_accuracy: 0.7839 - output_2_accuracy: 0.9755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f37ac179c482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     shuffle=True)\n\u001b[0m",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=img_data,\n",
    "    y=[img_data, onehot_encoded],\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vV1fM7i_w1yt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Hs3FHfObxGEL",
    "outputId": "c9e0ad65-f0fb-4b28-a484-a67867b58870"
   },
   "outputs": [],
   "source": [
    "model_1.save('2_3_2021_7am.tf')\n",
    "model_1.save_weights('2_3_2021_7am_weights.tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBEIr7GZxGEM"
   },
   "outputs": [],
   "source": [
    "np.save('img_datap',img_data)\n",
    "np.save('onehot_encodedp',onehot_encoded)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Moving_to_disk.ipynb",
   "provenance": [
    {
     "file_id": "1cgV9KNA566BFci-sQLaYXStXO3gZpi9T",
     "timestamp": 1613353654551
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
